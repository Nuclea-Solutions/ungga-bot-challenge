{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "071ac1f9-01c5-40bf-8343-ed31b0335fd9",
   "metadata": {},
   "source": [
    "# Ungga Challenge - Chatbot Asistente de agendación de citas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10e3b9a-e320-4654-909c-29ed52c80c0b",
   "metadata": {},
   "source": [
    "#### NOTA IMPORTANTE: De momento, el código que mejor muestra las capacidades del chatobt es el que se encuentra en la carpeta:\n",
    "\n",
    "    ungga-bot-challenge/backend/codigo_chatbot.py\n",
    "\n",
    "#### Esto es debido a que se hicieron múltiples pruebas del chatbot usando la consola. Y al final, para implementar el Frontend, hubo que modificar la estructura del chat, y debido al tiempo junto con los lentos periodos de ejecución, no se logró implementar en su totalidad (backend - frontend)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da91622d-0485-4c56-9b51-580f6c9e90e4",
   "metadata": {},
   "source": [
    "## 1. Instalar Ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8674c7-b69e-4a3e-8337-7c62ab56a173",
   "metadata": {},
   "source": [
    "#### Para poder ejecutar el chatbot, es requisito tener instalado Ollama de forma local en nuestro equipo. Este LLM se descarga desde la siguiente página:\n",
    "\n",
    "####    https://ollama.com/download\n",
    "\n",
    "#### Se descarga, se instala y luego en CMD se ejecutan el siguiente comando:\n",
    "\n",
    "    Ollama run llama3\n",
    "\n",
    "#### Esto descargará el modelo y lo ejecutará en un servidor local al cual se podrá acceder mediante API o de forma directa en LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c4bb80-8ac6-4457-8b88-0c3078991bae",
   "metadata": {},
   "source": [
    "## 2. Pasos para ejecución del código (Backend)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5752ef5d-9e70-460c-86b1-d0293577c01c",
   "metadata": {},
   "source": [
    "### NOTA: Hay que asegurarse de tener una base de datos MongoDB conectada al servidor local, en donde se guardarán las citas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68edd6a8-2009-4e85-aa99-8cc287cf4c0e",
   "metadata": {},
   "source": [
    "##### 1. Abrir carpeta '/ungga-bot-challenge/backend' en Visual Studio Code\n",
    "\n",
    "##### 2. Abrir la terminal Git Bash y ejecutar el siguiente comando para activar el entorno virtual:\n",
    "                source venv/Scripts/activate\n",
    "\n",
    "##### 3. Con el entorno virtual activo, se descargan las librerías usando el siguiente comando (con ejecutarlo en el entorno virtual una sola vez ya es suficiente, y servirá tanto para main.py coom para codigo_chatbot.py.)\n",
    "                pip install -r requirements.txt\n",
    "\n",
    "##### 4. Una vez se hayan descargado las librerías, ejecutar el archivo main.py con el siguiente comando en la terminal de Git Bash:\n",
    "                python main.py\n",
    "\n",
    "##### 5. Con esto el código debería estar ejecutándose.\n",
    "\n",
    "##### 6. (Extra) Para chatear con el bot desde la consola y ver todas sus capacidades, ejecutar el siguiente comando:\n",
    "                python codigo_chatbot.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1dcc7dd-bff1-4000-9ece-3f839a2a9e46",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 3. Pasos para ejecución del código (Frontend)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5cbe3f-ad59-46ae-8f3f-10ed00ab8b3f",
   "metadata": {},
   "source": [
    "##### 1. Abrir carpeta '/ungga-bot-challenge/frontend' en Visual Studio Code\n",
    "\n",
    "##### 2. Abrir la terminal Git Bash y ejecutar el siguiente comando para activar los módulos de npm:\n",
    "                npm install\n",
    "\n",
    "##### 3. Con los módulos ya instalados, para iniciar el front en un servidor local se ejecuta el siguiente comando:\n",
    "                npm run dev\n",
    "\n",
    "##### 5. Con esto el entorno React debería estar ejecutándose."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0bbdd6d-73ce-44a2-a53b-b0dba014ee44",
   "metadata": {},
   "source": [
    "# 2. Explicación del código (codigo_chatbot.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36380903-dcfb-4ed9-a339-b0f8712201e3",
   "metadata": {},
   "source": [
    "#### Primero debemos instalar las librerías necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e86a95cc-fdc0-4e8b-9ff6-72ae75a31028",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain langchain_community pymongo langgraph httpx -q\n",
    "# httpx fue instalado por un error que se daba en la importación de módulos desde langgraph (hay que investigar ahí)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651bb094-0654-4f48-845b-5832f71d407e",
   "metadata": {},
   "source": [
    "#### Luego importamos las funciones que usaremos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4766bb27-9904-4007-9f0d-0122058ffce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langgraph.graph import END, MessageGraph\n",
    "\n",
    "from pymongo import MongoClient                      # Para conectarnos con base de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879a9cfa-0c12-46ff-9ae3-ea51cf1718fc",
   "metadata": {},
   "source": [
    "#### Conexión con base de datos\n",
    "##### Hay que asegurarse de tener conectada la base de datos a algún puerto\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70a13ea9-518b-4d98-a701-04717b96aa9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient('localhost', 27017)\n",
    "database = client['Ungga-Challenge'] ### ------> Aqui debe insertar el nombre de la base de datos de MongoDBCompass local\n",
    "collection = database['citas'] ### -----------> Aquí debe insertar el nombre de la colección dentro de la base de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99469c0-57ea-430f-a299-a0d52833a489",
   "metadata": {},
   "source": [
    "#### Generamos un llm\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ec23175-5e87-4b30-8d63-826b3588de21",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Ollama(model=\"llama3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4174a4bc-1e98-4131-99af-d5ae5c9550ac",
   "metadata": {},
   "source": [
    "#### creamos un historial de chat vacío"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc680398-38af-4f04-8fb8-813c5f8ac0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0837e965-fa98-47f4-b5d0-a08b9700c3d1",
   "metadata": {},
   "source": [
    "#### PromptTemplate para el Agente_de_Citas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dff0fe9f-2522-4c07-8b1c-0184f0a50d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"Eres un AI que agenda citas, me debes ir preguntando mi información hasta obtener lo siguiente:\n",
    "            - nombre\n",
    "            - email\n",
    "            - horario de cita (día de la semana, día del mes, mes y hora), haz esto mensaje tras mensaje.\n",
    "            \n",
    "            Solamente cuando hayas obtenido todo, retornarás los datos en forma de diccionario: \n",
    "            'nombre': <nombre>, 'email': <email>, 'cita': <horario de la cita en MM/DD/2024 HH:MM>\n",
    "            No retornes nada extra más que eso, solamente el diccionario, ninguna palabra más.\"\"\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7002d9f1-6bf0-4ffe-a5b3-62f627f4b55c",
   "metadata": {},
   "source": [
    "#### Generamos la cadena"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db3f285b-c017-4cd0-9b1d-6b9ce96a6766",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt_template | llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da060c42-0ea6-4e2f-9ed3-a811af22b665",
   "metadata": {},
   "source": [
    "#### Función de Agente_de_citas\n",
    "##### Nos agendará una cita en la base de datos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0d45284-554b-417b-8744-0f7e3d5970f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(user_input):\n",
    "\n",
    "    # Inicializamos \"quiero agendar una cita\" o algo parecido que incluya la palabra \"cita\"\n",
    "    response = chain.invoke({\"input\": user_input, \"chat_history\": chat_history})\n",
    "    print(response)\n",
    "    chat_history.append(HumanMessage(content=response))  #siempre añadimos la info respectia al historial\n",
    "\n",
    "\n",
    "    # Nos quedaremos en este loop hasta haber agendado la cita\n",
    "    while True:\n",
    "        pregunta = input(\"You: \")\n",
    "\n",
    "        response = chain.invoke({\"input\": pregunta, \"chat_history\": chat_history})\n",
    "        chat_history.append(HumanMessage(content=pregunta))\n",
    "        chat_history.append(SystemMessage(content=response))\n",
    "        print(\"-\"*50)\n",
    "        print(\"AI: \" + response)\n",
    "        print(\"-\"*50)\n",
    "\n",
    "        datos_iniciales = response\n",
    "\n",
    "        # Al recolectar todos los datos, devolverá un diccionario\n",
    "        if datos_iniciales.startswith(\"{\"):\n",
    "            print(\"---------------out--------------\")\n",
    "            datos_diccionario = eval(datos_iniciales)\n",
    "            print(type(datos_diccionario))\n",
    "            print(datos_diccionario)\n",
    "            user_nombre = datos_diccionario['nombre']\n",
    "            print(user_nombre)\n",
    "            user_email = datos_diccionario['email']\n",
    "            print(user_email)\n",
    "            user_cita = datos_diccionario['cita']\n",
    "            print(user_cita)\n",
    "            print(\"---------------out--------------\")\n",
    "\n",
    "            # Pregunta si queremos confirmar la cita\n",
    "            confirmacion = \"Ahora que tienes los datos, pregúntame si quiero confirmar la cita. Si te digo que no, pregúntame qué quiero modificar, lo modificas y vuelves a retornar el diccionario. Si te respondo afirmativamente, debes retornar la palabra True, nada más\"\n",
    "            response = chain.invoke({\"input\": confirmacion, \"chat_history\": chat_history}) \n",
    "            chat_history.append(HumanMessage(content=confirmacion)) \n",
    "            chat_history.append(SystemMessage(content=response))\n",
    "            print(\"AI: \" + response)   \n",
    "            print(\"-\"*50)\n",
    "\n",
    "            pregunta = input(\"You: \") #aquí respondemos a si confirmamos o no\n",
    "            response = chain.invoke({\"input\": pregunta, \"chat_history\": chat_history}) \n",
    "            chat_history.append(HumanMessage(content=pregunta)) \n",
    "            chat_history.append(SystemMessage(content=response))\n",
    "            \n",
    "            # Si confirmamos, se guardan los datos del diccionario en la base de datos\n",
    "            if str(response) == \"True\":\n",
    "                print(\"---------------out--------------\")\n",
    "                collection.insert_one({\"name\":user_nombre, \"email\": user_email, \"cita\": user_cita})\n",
    "                print(\"cita agendada\")\n",
    "                print(\"---------------out--------------\")\n",
    "                return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3071142-0005-451e-a230-54277ab43e96",
   "metadata": {},
   "source": [
    "#### Con Langgraph generamos un Grafo, que contiene al Agente_traductor en un nodo, la traducción en otro y un Edge que los conecta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31907d3f-a6e9-484c-8b4c-6701fe05331d",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = MessageGraph()\n",
    "\n",
    "graph.add_node(\"oracle\", llm)\n",
    "graph.add_edge(\"oracle\", END)\n",
    "\n",
    "# Definimos punto de entrada\n",
    "graph.set_entry_point(\"oracle\")\n",
    "\n",
    "# Compilamos el grafo junto con nuestro llm\n",
    "runnable = graph.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4243d16-83ca-42d2-af57-a59bf7bb2ee8",
   "metadata": {},
   "source": [
    "#### Generamos una función para cambiar entre agentes dependiendo de las palabras clave que digan:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19f5f748-42c6-43b6-8a3d-4d87b65002af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encontrar_palabras_clave(string, palabras):\n",
    "    encontrar_palabras = []\n",
    "    for palabra in palabras:\n",
    "        if palabra in string:\n",
    "            encontrar_palabras.append(palabra)\n",
    "    return encontrar_palabras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493fd37b-3175-4fb6-b9a2-25d799a0a4e9",
   "metadata": {},
   "source": [
    "#### Definimos el chat principal con el Agente_traductor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24b56435-604f-46b1-8bfa-f3eb11ea69d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_main(user_input):\n",
    "\n",
    "    # definimos un historial de chat manual para el Agente Conversacional #3\n",
    "    store1 = []\n",
    "    user_input = \"\"\n",
    "    \n",
    "    # Este será la IA que reciba al usuario\n",
    "    system_input = \"Eres un chatbot que puede traducir lo que sea. También puedes agendar citas. Comienza dándome la bienvenida.\"\n",
    "    store1.append(\"System: \" + system_input)\n",
    "    primer_mensaje = runnable.invoke(HumanMessage(system_input))\n",
    "    store1.append(\"AI: \" + primer_mensaje[-1].content)\n",
    "    print(\"AI: \" + primer_mensaje[-1].content)\n",
    "    print(\"-\"*50)\n",
    "    \n",
    "    # Aquí comienza el chat Loop, si el Usuario menciona \"cita\", se activará el agente de citas\n",
    "    while user_input != \"terminar\":\n",
    "\n",
    "        # user_input = input(\"Ingrese mensaje: \")\n",
    "        user_input = input(\"You: \")\n",
    "        store1.append(\"Human: \" + user_input)\n",
    "        palabras_clave_cita = [\"cita\", \"citas\", \"appointment\", \"appointments\"]\n",
    "        iniciar_cita = encontrar_palabras_clave(user_input, palabras_clave_cita)\n",
    "\n",
    "        # Si está escrita la palabra \"cita\", se inicia el chat con el otro agente\n",
    "        if len(iniciar_cita)>0:\n",
    "            chat(user_input)\n",
    "            \n",
    "        #Al finalizar el chat de agendar citas, se puede seguir conversando con el Agente Conversacional #3\n",
    "        respuesta = runnable.invoke(HumanMessage(user_input))\n",
    "        store1.append(\"AI: \" + respuesta[-1].content)\n",
    "        print(\"-\"*50)\n",
    "        print(\"AI: \" + respuesta[-1].content)\n",
    "        print(\"-\"*50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6158ce8d-ff3d-4034-bf90-20fe2d6e5a08",
   "metadata": {},
   "source": [
    "#### Finalmente iniciamos el código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8bbe83d7-1c88-471a-b175-eb4e36554e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: ¡Hola!\n",
      "\n",
      "Me alegra poder saludarte y hacerme cargo de tu tiempo. Soy un chatbot altamente especializado en traducción, con capacidad para interpretar y responder a una variedad de preguntas y solicitudes.\n",
      "\n",
      "Estoy aquí para ayudarte en todo lo que necesites, desde traducir textos o documentos hasta agendar citas y realizar tareas administrativas. No dudes en preguntarme algo, ¡estoy listo!\n",
      "\n",
      "¿En qué puedo ayudarte hoy?\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  hola, quiero saber cómo puedo decir \"tengo sueño\" en francés\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "AI: Hola!\n",
      "\n",
      "La traducción de \"tengo sueño\" al francés es \"j'ai sommeil\".\n",
      "\n",
      "* \"Tengo\" se traduce a \"j'ai\"\n",
      "* \"sueño\" se traduce a \"sommeil\"\n",
      "\n",
      "Por lo tanto, la respuesta correcta sería: \"J'ai sommeil.\"\n",
      "\n",
      "Si deseas decir \"estoy cansado(a)\" en francés, podrías usar la frase \"J'ai besoin de sommeil\" (necesito dormir) o simplemente \"Je suis fatigué(e)\" (estoy cansado(a)).\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  how can i say \"i'm hungry\" in spanish?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "AI: To say \"I'm hungry\" in Spanish, you can say:\n",
      "\n",
      "Estoy hambriento(a).\n",
      "\n",
      "Here's a breakdown of the sentence:\n",
      "\n",
      "* Estoy means \"I am\"\n",
      "* Hambriento(a) is the adjective that means \"hungry\"\n",
      "\n",
      "Note: The verb \"estar\" (to be) is used to describe temporary or changing situations, such as hunger. If you're saying you're always hungry, you might use the verb \"ser\" (to be) instead:\n",
      "\n",
      "Soy hambriento(a).\n",
      "\n",
      "But if you're talking about a specific moment when you feel hungry, then \"estar\" is the way to go!\n",
      "\n",
      "Hope that helps!\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  Gracias. Quiero agendar una cita\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Genial! Empecemos. ¿Cuál es tu nombre?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  me llamo Osvaldo\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "AI: ¿Cuál es tu dirección de correo electrónico?\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  osvaldo123@email.com\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "AI: ¿Qué día y hora te gustaría programar para la cita? (Día de la semana, día del mes, mes y hora)\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  lunes 27 de mayo a las 13:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "AI: {'nombre': 'Osvaldo', 'email': 'osvaldo123@email.com', 'cita': '05/27/2024 13:00'}\n",
      "--------------------------------------------------\n",
      "---------------out--------------\n",
      "<class 'dict'>\n",
      "{'nombre': 'Osvaldo', 'email': 'osvaldo123@email.com', 'cita': '05/27/2024 13:00'}\n",
      "Osvaldo\n",
      "osvaldo123@email.com\n",
      "05/27/2024 13:00\n",
      "---------------out--------------\n",
      "AI: ¡Excelente! Quiero confirmar la cita.\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  si\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------out--------------\n",
      "cita agendada\n",
      "---------------out--------------\n",
      "--------------------------------------------------\n",
      "AI: ¡Excelente elección! Me alegra que estés interesado en programar una cita conmigo.\n",
      "\n",
      "¿Cuál es el horario y fecha que te parece más conveniente para ti? Tenemos disponibles varios horarios y fechas, por lo que no hay problema en encontrar uno que se adapte a tus necesidades.\n",
      "\n",
      "Además, ¿hay algún lugar o actividad específica que tengas en mente para nuestra cita? Me gustaría saber para poder planificar algo especial y personalizado para ti.\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  ¿cuantos planetas hay en el sistema solar?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "AI: Una pregunta clásica!\n",
      "\n",
      "En el sistema solar, hay ocho planetas que se consideran \"plenetes\" (planets) reconocidos por la Unión Astronómica Internacional (UAI):\n",
      "\n",
      "1. Mercurio\n",
      "2. Venus\n",
      "3. Tierra\n",
      "4. Marte\n",
      "5. Jupiter (Júpiter)\n",
      "6. Saturno\n",
      "7. Uranus\n",
      "8. Neptuno\n",
      "\n",
      "Además, existen otros cuerpos menores que orbitan alrededor del Sol, como:\n",
      "\n",
      "* Los planetas enanos: Ceres (que es el más grande de los asteroides), Pluto y sus satélites, Eris, Haumea y Makemake.\n",
      "* Los asteroides: Miles de pequeños objetos rocosos que orbitan entre Mercurio y Marte.\n",
      "* Los cometas: Se cree que hay millones de cometas en el sistema solar, aunque solo unos pocos son visibles desde la Tierra.\n",
      "\n",
      "En resumen, en el sistema solar hay ocho planetas \"plenetes\" reconocidos, pero muchos otros objetos menores que orbitan alrededor del Sol.\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  terminar\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "AI: Entendi!\n",
      "\n",
      "Você deseja que eu termine nossa conversa, não é?\n",
      "\n",
      "Sinta-se à vontade para me dizer o motivo pelo qual você quer encerrar a nossa conversa. Se tiver alguma sugestão ou feedback para melhorar nossa interação, estou aqui para escutar!\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "chat_main(\"hola\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
